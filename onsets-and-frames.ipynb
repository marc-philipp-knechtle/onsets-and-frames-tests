{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "Onsets and Frames.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gYGMczS-7rkJ"
   },
   "source": [
    "Copyright 2020 Google LLC.\n",
    "\n",
    "Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "you may not use this file except in compliance with the License.\n",
    "You may obtain a copy of the License at\n",
    "\n",
    "https://www.apache.org/licenses/LICENSE-2.0\n",
    "\n",
    "Unless required by applicable law or agreed to in writing, software\n",
    "distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "See the License for the specific language governing permissions and\n",
    "limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IiIFvcvy7dH5"
   },
   "source": [
    "# Onsets and Frames Transcription\n",
    "\n",
    "Onsets and Frames is an automatic music transcription framework with piano and drums models. This notebook demonstrates running the model on user-supplied recordings. For more details on the architecture of the model and training datasets, see our papers:\n",
    "\n",
    "* [Onsets and Frames: Dual-Objective Piano Transcription](https://goo.gl/magenta/onsets-frames-paper)\n",
    "* [Enabling Factorized Piano Music Modeling and Generation with the MAESTRO Dataset](https://goo.gl/magenta/maestro-paper)\n",
    "* [Improving Perceptual Quality of Drum Transcription with the Expanded Groove MIDI Dataset](https://goo.gl/magenta/e-gmd-paper)\n",
    "\n",
    "And blog posts:\n",
    "\n",
    "* [Onsets and Frames: Dual-Objective Piano Transcription\n",
    "](http://g.co/magenta/onsets-frames)\n",
    "* [The MAESTRO Dataset and Wave2Midi2Wave](https://g.co/magenta/maestro-wave2midi2wave)\n",
    "* [Improving Perceptual Quality of Drum Transcription with the Expanded Groove MIDI Dataset](https://g.co/magenta/oaf-drums)\n",
    "---\n",
    "\n",
    "This colab notebook is self-contained and should run natively on google cloud. The code and checkpoints can be downloaded separately and run locally, which is recommended if you want to train your own model. Details on how to do this can be found in the [GitHub repo](https://goo.gl/magenta/onsets-frames-code)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j79eR9mp_oaH"
   },
   "source": [
    "# Environment Setup\n",
    "\n",
    "Includes package installation for sequence synthesis and downloading pretrained checkpoint. May take a few minutes."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "nzGyqJja7I0O",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "7e296fdf-6db3-4eee-8e88-e2791a5dec4f",
    "ExecuteTime": {
     "end_time": "2023-11-22T19:42:12.424194351Z",
     "start_time": "2023-11-22T19:42:12.416376693Z"
    }
   },
   "source": [
    "#@title Setup Environment\n",
    "\n",
    "import glob\n",
    "import os\n",
    "\n",
    "# print('Copying checkpoints from GCS...')\n",
    "# !rm -r /content/onsets-frames\n",
    "# !mkdir /content/onsets-frames\n",
    "# !gsutil -q -m cp -R gs://magentadata/models/onsets_frames_transcription/*checkpoint*.zip /content/onsets-frames/\n",
    "# !unzip -o /content/onsets-frames/maestro_checkpoint.zip -d /content/onsets-frames/maestro\n",
    "# !unzip -o /content/onsets-frames/e-gmd_checkpoint.zip -d /content/onsets-frames/e-gmd\n",
    "# \n",
    "# print('Installing dependencies...')\n",
    "# !apt-get update -qq && apt-get install -qq libfluidsynth2 fluid-soundfont-gm build-essential libasound2-dev libjack-dev ffmpeg\n",
    "# !pip install cython wheel\n",
    "# !pip install pyfluidsynth pretty_midi python-rtmidi\n",
    "# \n",
    "# !pip install -qU magenta\n",
    "\n",
    "print(\"Skipping all of this process because of manual setup.\")"
   ],
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping all of this process because of manual setup.\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Commands used to create the appropriate environment\n",
    "# !pip3 install -c constraints.txt magenta==2.1.4\n",
    "!python3.10 -m venv.venv\n",
    "!pip3 install -r requirements.txt\n",
    "!pip3 install --no-deps magenta == 2.1.4"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Commands used to create the conda venv for magenta\n",
    "!conda craete -n magenta python=3.7\n",
    "!source activate magenta\n",
    "!pip3 install python-rtmidi == 1.1.2\n",
    "!pip3 install magenta == 1.1.8"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "MAESTRO_CHECKPOINT_DIR = '/content/onsets-frames/maestro/train'\n",
    "EGMD_CHECKPOINT_DIR = '/content/onsets-frames/e-gmd'"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-22T23:05:14.902126102Z",
     "start_time": "2023-11-22T23:05:14.892824258Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RE-Z_a6UCAf2"
   },
   "source": [
    "# Model Initializiation"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "u3EyI4V4y4Zn",
    "ExecuteTime": {
     "end_time": "2023-11-22T23:05:20.591867334Z",
     "start_time": "2023-11-22T23:05:20.583554339Z"
    }
   },
   "source": [
    "#@title Select Model\n",
    "model_type = \"MAESTRO (Piano)\"  #@param [\"MAESTRO (Piano)\", \"E-GMD (Drums)\"]\n"
   ],
   "execution_count": 4,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "n8GJ5pRc6biH",
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 387
    },
    "outputId": "47e6fd11-0924-409f-dedf-800f72975d34",
    "ExecuteTime": {
     "end_time": "2023-11-27T11:28:41.182585772Z",
     "start_time": "2023-11-27T11:28:40.972973927Z"
    }
   },
   "source": [
    "#@title Initialize Model\n",
    "# import tensorflow as tf\n",
    "# original import from file\n",
    "import tensorflow.compat.v1 as tf\n",
    "# workaround posted in: https://github.com/tensorflow/tensorflow/issues/38800\n",
    "# (workaround for above command)\n",
    "# import tensorflow._api.v2.compat.v1 as tf\n",
    "\n",
    "\n",
    "import librosa\n",
    "import numpy as np\n",
    "\n",
    "# commenting this because of local execution\n",
    "# from google.colab import files\n",
    "\n",
    "# present in original code\n",
    "# from magenta.common import tf_utils\n",
    "from magenta.models.onsets_frames_transcription import audio_label_data_utils\n",
    "from magenta.models.onsets_frames_transcription import configs\n",
    "from magenta.models.onsets_frames_transcription import constants\n",
    "from magenta.models.onsets_frames_transcription import data\n",
    "from magenta.models.onsets_frames_transcription import infer_util\n",
    "from magenta.models.onsets_frames_transcription import train_util\n",
    "# note_seq is disabled because of duplicate music.proto file\n",
    "from note_seq import audio_io\n",
    "import note_seq\n",
    "from note_seq import midi_io\n",
    "from note_seq import sequences_lib\n",
    "\n",
    "tf.disable_v2_behavior()\n",
    "\n",
    "## Define model and load checkpoint\n",
    "## Only needs to be run once.\n",
    "\n",
    "if model_type.startswith('MAESTRO'):\n",
    "    config = configs.CONFIG_MAP['onsets_frames']\n",
    "    hparams = config.hparams\n",
    "    hparams.use_cudnn = False\n",
    "    hparams.batch_size = 1\n",
    "    checkpoint_dir = MAESTRO_CHECKPOINT_DIR\n",
    "elif model_type.startswith('E-GMD'):\n",
    "    config = configs.CONFIG_MAP['drums']\n",
    "    hparams = config.hparams\n",
    "    hparams.batch_size = 1\n",
    "    checkpoint_dir = EGMD_CHECKPOINT_DIR\n",
    "else:\n",
    "    raise ValueError('Unknown Model Type')\n",
    "\n",
    "examples = tf.placeholder(tf.string, [None])\n",
    "\n",
    "dataset = data.provide_batch(\n",
    "    examples=examples,\n",
    "    preprocess_examples=True,\n",
    "    params=hparams,\n",
    "    is_training=False,\n",
    "    shuffle_examples=False,\n",
    "    skip_n_initial_records=0)\n",
    "\n",
    "estimator = train_util.create_estimator(\n",
    "    config.model_fn, checkpoint_dir, hparams)\n",
    "\n",
    "iterator = tf.data.make_initializable_iterator(dataset)\n",
    "next_record = iterator.get_next()"
   ],
   "execution_count": 33,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_model_dir': '/content/onsets-frames/maestro/train', '_tf_random_seed': None, '_save_summary_steps': 300, '_save_checkpoints_steps': 300, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': None, '_keep_checkpoint_every_n_hours': 1, '_log_step_count_steps': None, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fa74902a2d0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_tpu_config': TPUConfig(iterations_per_loop=300, num_shards=None, num_cores_per_replica=None, per_host_input_for_training=2, tpu_job_name=None, initial_infeed_sleep_secs=None, input_partition_dims=None, eval_training_input_configuration=2, experimental_host_call_every_n_steps=1), '_cluster': None}\n",
      "INFO:tensorflow:_TPUContext: eval_on_tpu False\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qFiGvUBaCM9_"
   },
   "source": [
    "# Upload Audio\n",
    "\n",
    "Run the following cell to upload audio files."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "AxmkX4Tu5UJd",
    "cellView": "form",
    "outputId": "7831c48a-1a3f-48a8-8005-e14c867d4ded",
    "colab": {
     "resources": {
      "http://localhost:8080/nbextensions/google.colab/files.js": {
       "data": "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",
       "ok": true,
       "headers": [
        [
         "content-type",
         "application/javascript"
        ]
       ],
       "status": 200,
       "status_text": ""
      }
     },
     "base_uri": "https://localhost:8080/",
     "height": 105
    },
    "ExecuteTime": {
     "end_time": "2023-11-23T12:27:22.485649509Z",
     "start_time": "2023-11-23T12:27:22.413443754Z"
    }
   },
   "source": [
    "from typing import List\n",
    "import os\n",
    "\n",
    "# from original jupyter code\n",
    "#@title Audio Upload\n",
    "# uploaded = files.upload()\n",
    "\n",
    "directory_path: str = 'files-to-process'\n",
    "uploaded: List[str] = os.listdir(directory_path)\n",
    "\n",
    "to_process: List[str] = []\n",
    "\"\"\"\n",
    "This is a list of binary string of the data which is to be converted. The binary strings are created using the .SerializeToString method. \n",
    "TF documentation: All proto messages can be serialized to a binary-string using the .SerializeToString method:\n",
    "\"\"\"\n",
    "# for fn in uploaded:\n",
    "#     with open(os.path.join(directory_path, fn)) as file_content:\n",
    "#         print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
    "#             name=fn, length=file_content.__sizeof__()))\n",
    "#         wav_data = file_content\n",
    "#         record = audio_label_data_utils.process_record(\n",
    "#             wav_data=wav_data,\n",
    "#             sample_rate=hparams.sample_rate,\n",
    "#             ns=note_seq.NoteSequence(),\n",
    "#             example_id=fn,\n",
    "#             min_length=0,\n",
    "#             max_length=-1,\n",
    "#             allow_empty_notesequence=True)\n",
    "#         print(type(record))\n",
    "#         first = next(record).SerializeToString()\n",
    "#         # print(str(type(first)))\n",
    "#         # example_list = list(record)\n",
    "#         # assert len(example_list) == 1\n",
    "#         to_process.append(first.SerializeToString())\n",
    "# \n",
    "#         print('Processing complete for', fn)\n",
    "\n",
    "sess = tf.Session()\n",
    "\n",
    "sess.run([\n",
    "    tf.initializers.global_variables(),\n",
    "    tf.initializers.local_variables()\n",
    "])\n",
    "\n",
    "# sess.run(iterator.initializer, {examples: to_process})\n",
    "# \n",
    "# \n",
    "# def transcription_data(params):\n",
    "#     del params\n",
    "#     return tf.data.Dataset.from_tensors(sess.run(next_record))\n",
    "# \n",
    "# \n",
    "# input_fn = infer_util.labels_to_features_wrapper(transcription_data)"
   ],
   "execution_count": 32,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-23 13:27:22.412749: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "2023-11-23 13:27:22.423502: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3599840000 Hz\n",
      "2023-11-23 13:27:22.424219: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x129a480 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2023-11-23 13:27:22.424230: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n"
     ]
    },
    {
     "data": {
      "text/plain": "[None, None]"
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "directory_path: str = 'files-to-process'\n",
    "uploaded: List[str] = os.listdir(directory_path)\n",
    "\n",
    "for filename in uploaded:\n",
    "    print('Starting transcription for %s...', filename)\n",
    "    sess.run(iterator.initializer, )\n",
    "    "
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lMimufLfNMMq"
   },
   "source": [
    "# Inference\n",
    "\n",
    "Run the following cell to transcribe the files you uploaded. Each time it runs it will transcribe one of the uploaded files."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Z5SYRvIm8gq5",
    "outputId": "1ded49e3-ddca-49e7-8870-02b93e5df603",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 248
    }
   },
   "source": [
    "#@title Run inference\n",
    "prediction_list = list(\n",
    "    estimator.predict(\n",
    "        input_fn,\n",
    "        yield_single_examples=False))\n",
    "assert len(prediction_list) == 1\n",
    "\n",
    "sequence_prediction = note_seq.NoteSequence.FromString(\n",
    "    prediction_list[0]['sequence_predictions'][0])\n",
    "\n",
    "# Ignore warnings caused by pyfluidsynth\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "\n",
    "note_seq.plot_sequence(sequence_prediction)\n",
    "note_seq.play_sequence(sequence_prediction, note_seq.midi_synth.fluidsynth,\n",
    "                       colab_ephemeral=False)"
   ],
   "execution_count": 5,
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "ignored",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-5-e1a8ca7fed1d>\u001B[0m in \u001B[0;36m<cell line: 2>\u001B[0;34m()\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[0;31m#@title Run inference\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      2\u001B[0m prediction_list = list(\n\u001B[0;32m----> 3\u001B[0;31m     estimator.predict(\n\u001B[0m\u001B[1;32m      4\u001B[0m         \u001B[0minput_fn\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      5\u001B[0m         yield_single_examples=False))\n",
      "\u001B[0;31mNameError\u001B[0m: name 'estimator' is not defined"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FFDVTcMwj5VX"
   },
   "source": [
    "Optionally run the following cell to download a MIDI version of the inferred transcription."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "3JnQW-Gaj-5d",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 248
    },
    "outputId": "d5876797-21f2-4314-87ad-ed472318ca5c"
   },
   "source": [
    "#@title Download MIDI\n",
    "midi_filename = ('prediction.mid')\n",
    "midi_io.sequence_proto_to_midi_file(sequence_prediction, midi_filename)\n",
    "\n",
    "files.download(midi_filename)"
   ],
   "execution_count": 6,
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "ignored",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-6-56b9aef03b5d>\u001B[0m in \u001B[0;36m<cell line: 3>\u001B[0;34m()\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[0;31m#@title Download MIDI\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      2\u001B[0m \u001B[0mmidi_filename\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0;34m'prediction.mid'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 3\u001B[0;31m \u001B[0mmidi_io\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msequence_proto_to_midi_file\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0msequence_prediction\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmidi_filename\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      4\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      5\u001B[0m \u001B[0mfiles\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdownload\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmidi_filename\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mNameError\u001B[0m: name 'midi_io' is not defined"
     ]
    }
   ]
  }
 ]
}
